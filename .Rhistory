ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
# split into words
by_chapter_word <- by_chapter %>%
unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
word_counts
library(topicmodels)
# Создание документа-терм матрицы (dtm)
dtm <- create_dtm(by_chapter_word$word, document = by_chapter_word$document)
# Создание документа-терм матрицы (dtm)
dtm <- topicmodels::create_dtm(by_chapter_word$word, document = by_chapter_word$document)
install.packages("text2vec")
library(tm)
library(tidytext)
library(topicmodels)
# Создание DTM
dtm <- word_counts %>%
cast_dtm(document, word, n)
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
# Создание DTM
dtm <- word_counts %>%
cast_dtm(document, word, n)
# Преобразование в tf-idf
tfidf <- transform(dtm, "tfidf")
# Преобразование в tf-idf
tfidf <- tm::transform(dtm, "tfidf")
# Преобразование в tf-idf
tfidf <- tm::weightTfIdf(dtm)
print(tfidf)
# Проведение LDA
lda_model <- LDA(tfidf, k = 3)  # Установите желаемое количество тем в параметре k
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
# Создание DTM с взвешиванием частоты терминов
dtm <- word_counts %>%
cast_dtm(document, word, n, weight = weightTf)
# Проведение LDA
lda_model <- topicmodels::LDA(tfidf, k = 3)
# Проведение LDA
lda_model <- topicmodels::LDA(dtm, k = 3)
chapter_topics <- tidy(lda_model, matrix = "beta")
chapter_topics
top_terms <- chapter_topics %>%
group_by(topic) %>%
top_n(5, beta) %>%
ungroup() %>%
arrange(topic, -beta)
library(ggplot2)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
shiny::runApp()
tfidf <- tm::weightTfIdf(dtm)
# Проведение LDA
lda_model <- topicmodels::LDA(tfidf, k = 3)
# Создание DTM с взвешиванием частоты терминов
dtm <- word_counts %>%
cast_dtm(document, word, n, weight = weightTfIdf)
#tfidf <- tm::weightTfIdf(dtm)
# Проведение LDA
lda_model <- topicmodels::LDA(dtm, k = 3)
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
JSS_dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
JSS_dtm
# Преобразование в матрицу TF-IDF
term_tfidf <- JSS_dtm * log2(nDocs(JSS_dtm) / col_sums(JSS_dtm > 0))
# Преобразование в матрицу TF-IDF
term_tfidf <- JSS_dtm * log2(nDocs(JSS_dtm) / Matrix::col_sums(JSS_dtm > 0))
term_tfidf <-
tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
term_tfidf <-
tapply(JSS_dtm$v/Matrix::row_sums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/Matrix::col_sums(JSS_dtm > 0))
term_tfidf <-
tapply(JSS_dtm$v/Matrix::rowSums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/Matrix::col_sums(JSS_dtm > 0))
term_tfidf <-
tapply(JSS_dtm$v/Matrix::rowSums(JSS_dtm, dims = 2)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/Matrix::col_sums(JSS_dtm > 0))
# Вычисление TF
TF <- JSS_dtm / rowSums(JSS_dtm)
# Вычисление TF-IDF
term_tfidf <- TF * IDF
# Создание модели LDA
lda_model <- topicmodels::LDA(term_tfidf, k = 3)
# Преобразование JSS_dtm в матрицу
JSS_matrix <- as.matrix(JSS_dtm)
# Вычисление TF
TF <- JSS_matrix / rowSums(JSS_matrix)
# Вычисление IDF
total_docs <- nrow(JSS_matrix)
non_zero_terms <- colSums(JSS_matrix > 0)
IDF <- log2(total_docs / non_zero_terms)
# Вычисление TF-IDF
term_tfidf <- TF * IDF
print(term_tfidf)
term_tfidf
term_tfidf
# Создание модели LDA
lda_model <- topicmodels::LDA(term_tfidf, k = 3)
dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
print(dtm)
df <- as.data.frame(dtm)
df <- as.matrix.frame(dtm)
df <- as.matrix(dtm)
View(df[1:5, 1:5])
View(df)
??rowSums
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
JSS_dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
print(dtm)
df <- as.matrix(dtm)
View(df)
library(slam)
term_tfidf <-
tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
print(term_tfidf)
JSS_dtm <- JSS_dtm[,term_tfidf >= 0.1]
JSS_dtm <- JSS_dtm[row_sums(JSS_dtm) > 0,]
print(JSS_dtm)
df <- as.matrix(JSS_dtm)
View(JSS_dtm)
library(gutenbergr)
books <- gutenberg_download(c(1268, 33111, 1074), meta_fields = "title", mirror = "http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/")
books
library(stringr)
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
library(gutenbergr)
books <- gutenberg_download(c(1268, 33111, 1074), meta_fields = "title", mirror = "http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/")
books
library(stringr)
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
library(stringr)
library(tydir)
library(stringr)
library(tidytext)
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
library(shiny)
library(shinyWidgets)
library(shinydashboard)
library(gutenbergr)
library(tidytext)
library(tidyr)
library(dplyr)
library(stringr)
library(DT)
library(readr)
library(data.table)
library(gutenbergr)
books <- gutenberg_download(c(1268, 33111, 1074), meta_fields = "title", mirror = "http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/")
books
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
# split into words
by_chapter_word <- by_chapter %>%
unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
word_counts
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
JSS_dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
print(dtm)
df <- as.matrix(dtm)
View(df)
library(slam)
term_tfidf <-
tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
JSS_dtm <- JSS_dtm[,term_tfidf >= 0.1]
JSS_dtm <- JSS_dtm[row_sums(JSS_dtm) > 0,]
print(JSS_dtm)
lda_model <- topicmodels::LDA(JSS_dtm, k = 3)
# Создание модели LDA
lda_model <- topicmodels::LDA(JSS_dtm, k = 3)
chapter_topics <- tidy(lda_model, matrix = "beta")
library(shiny)
library(shinyWidgets)
library(shinydashboard)
library(gutenbergr)
library(tidytext)
library(tidyr)
library(dplyr)
library(stringr)
library(DT)
library(readr)
library(data.table)
library(gutenbergr)
books <- gutenberg_download(c(1268, 33111, 1074), meta_fields = "title", mirror = "http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/")
books
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
# split into words
by_chapter_word <- by_chapter %>%
unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
word_counts
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
JSS_dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
library(Matrix)
term_tfidf <-
tapply(JSS_dtm$v/row_sums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/col_sums(JSS_dtm > 0))
JSS_dtm <- JSS_dtm[,term_tfidf >= 0.1]
JSS_dtm <- JSS_dtm[row_sums(JSS_dtm) > 0,]
print(JSS_dtm)
# Создание модели LDA
lda_model <- topicmodels::LDA(JSS_dtm, k = 3)
chapter_topics <- tidy(lda_model, matrix = "beta")
library(shiny)
library(shinyWidgets)
library(shinydashboard)
library(gutenbergr)
library(tidytext)
library(tidyr)
library(dplyr)
library(stringr)
library(DT)
library(readr)
library(data.table)
library(gutenbergr)
books <- gutenberg_download(c(1268, 33111, 1074), meta_fields = "title", mirror = "http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/")
books
# divide into documents, each representing one chapter
reg <- regex("chapter", ignore_case = TRUE)
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, reg))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
# split into words
by_chapter_word <- by_chapter %>%
unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
word_counts
library(tm)
library(tidytext)
library(topicmodels)
library(dplyr)
JSS_dtm <- DocumentTermMatrix(word_counts,
control = list(stemming = TRUE,
stopwords = TRUE,
minWordLength = 3,
removeNumbers = TRUE,
removePunctuation = TRUE))
library(Matrix)
term_tfidf <-
tapply(JSS_dtm$v/rowSums(JSS_dtm)[JSS_dtm$i], JSS_dtm$j, mean) *
log2(nDocs(JSS_dtm)/colSums(JSS_dtm > 0))
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
View(lda_model)
View(TF)
View(df)
View(JSS_dtm)
runApp()
gc()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
gc()
gc()
gc()
shiny::runApp()
runApp()
shiny::runApp()
install.packages(c("backports", "BH", "brio", "broom", "bslib", "cachem", "callr", "cli", "cowplot", "cpp11", "crosstalk", "curl", "desc", "digest", "dplyr", "emmeans", "estimability", "FactoMineR", "fansi", "farver", "fastmap", "fs", "ggrepel", "ggsci", "glue", "gplots", "gtable", "gtools", "highr", "htmltools", "htmlwidgets", "httpuv", "jsonlite", "knitr", "later", "lme4", "minqa", "multcompView", "munsell", "mvtnorm", "openssl", "pkgbuild", "pkgload", "processx", "promises", "ps", "quantreg", "Rcpp", "RcppEigen", "readr", "rJava", "rlang", "rmarkdown", "sass", "SparseM", "stringi", "testthat", "tidyr", "tidyselect", "tinytex", "tm", "vctrs", "viridis", "withr", "xfun", "yaml"))
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
#Матрица ошибок
output$errorMatrix <- renderPlot({
req(assignments(), input$makeErrors)
data <- assignments()яЦ %>%
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
#Вывод перплексии
output$perplexityText <- renderText({
req(perplexityVal())
paste("Значение перплексии для модели:", round(abs(perplexityVal()), digits = 2))
})
shiny::runApp()
reactlog::reactlog_enable()
install.packages("reactlog")
reactlog::reactlog_enable()
shiny::runApp()
runApp()
shiny::runApp('C:/Users/DmiGu/Desktop/topicModelingTrainer3.0')
reactlog::reactlog_enable()
runApp('C:/Users/DmiGu/Desktop/topicModelingTrainer3.0')
runApp('C:/Users/DmiGu/Desktop/topicModelingTrainer3.0')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
